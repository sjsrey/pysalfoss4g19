{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Data Processing with libpysal,  Pandas and Geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By convention, we use these shorter names\n",
    "import pysal as ps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pysal.lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pysal.lib has a command that it uses to get the paths of its example datasets. Let's work with a commonly-used dataset first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps.lib.examples.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.lib.examples.explain('us_income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = ps.lib.examples.get_path('usjoin.csv')\n",
    "csv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ps.lib.io.open(csv_path)\n",
    "f.header[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2009 = f.by_col('2009')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2009[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work with local files outside the built-in examples.\n",
    "\n",
    "To read in a shapefile, we will need the path to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = 'data/texas.shp'\n",
    "print(shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we open the file using the `ps.io.open` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ps.lib.io.open(shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f` is what we call a \"file handle.\" That means that it only *points* to the data and provides ways to work with it. By itself, it does not read the whole dataset into memory. To see basic information about the file, we can use a few different methods. \n",
    "\n",
    "For instance, the header of the file, which contains most of the metadata about the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually read in the shapes from memory, you can use the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.by_row(14) # gets the 14th shape from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polygons = f.read() # reads in all polygons from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, all 254 polygons have been read in from file. These are stored in libpysal shape objects, which can be used by libpysal and can be converted to other Python shape objects.\n",
    "\n",
    "They typically have a few methods. So, since we've read in polygonal data, we can get some properties about the polygons. Let's just have a look at the first polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polygons[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polygons[0].centroid #the centroid of the first polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polygons[0].area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polygons[0].perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While in the Jupyter Notebook, you can examine what properties an object has by using the tab key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon = all_polygons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon. #press tab when the cursor is right after the dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf_path = \"data/texas.dbf\"\n",
    "print(dbf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're working with tables of data, like a `csv` or `dbf`, you can extract your data in the following way. Let's open the dbf file we got the path for above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ps.lib.io.open(dbf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with the shapefile, we can examine the header of the dbf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the header is a list containing the names of all of the fields we can read.\n",
    "If we just wanted to grab the data of interest, `HR90`, we can use either `by_col` or `by_col_array`, depending on the format we want the resulting data in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR90 = f.by_col('HR90')\n",
    "print(type(HR90).__name__, HR90[0:5])\n",
    "HR90 = f.by_col_array('HR90')\n",
    "print(type(HR90).__name__, HR90[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `by_col` function returns a list of data, with no shape. It can only return one column at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRs = f.by_col('HR90', 'HR80')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error message is called a \"traceback,\" as you see in the top right, and it usually provides feedback on why the previous command did not execute correctly. Here, you see that one-too-many arguments was provided to `__call__`, which tells us we cannot pass as many arguments as we did to `by_col`.\n",
    "\n",
    "If you want to read in many columns at once and store them to an array, use `by_col_array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRs = f.by_col_array('HR90', 'HR80')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best to use `by_col_array` on data of a single type. That is, if you read in a lot of columns, some of them numbers and some of them strings, all columns will get converted to the same datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcolumns = f.by_col_array(['NAME', 'STATE_NAME', 'HR90', 'HR80'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcolumns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the numerical columns, `HR90` & `HR80` are now considered strings, since they show up with the single tickmarks around them, like `'0.0'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods work similarly for `.csv` files as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopandas & pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_path = ps.lib.examples.get_path('NAT.shp')\n",
    "data_table = gpd.read_file(shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in *the entire database table* and adds a column to the end, called `geometry`, that stores the geometries read in from the shapefile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `read_file` function only works on shapefile/dbf pairs. If you need to read in data using CSVs, use pandas directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = ps.lib.examples.get_path('usjoin.csv')\n",
    "usjoin = pd.read_csv(csv_path)\n",
    "#usjoin = ps.pdio.read_files(csv_path) #will not work, not a shp/dbf pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.read_file(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usjoin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about working with geopandas dataframes is that they have very powerful baked-in support for relational-style queries. By this, I mean that it is very easy to find things like:\n",
    "\n",
    "The number of counties in each state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.groupby(\"STATE_NAME\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, to get the rows of the table that are in Arizona, we can use the `query` function of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.query('STATE_NAME == \"Arizona\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, this uses a fast vectorized library, `numexpr`, to essentially do the following. \n",
    "\n",
    "First, compare each row's `STATE_NAME` column to `'Arizona'` and return `True` if the row matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.STATE_NAME == 'Arizona'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use that to filter out rows where the condition is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[data_table.STATE_NAME == 'Arizona']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might need this behind the scenes knowledge when we want to chain together conditions, or when we need to do spatial queries. \n",
    "\n",
    "This is because spatial queries are somewhat more complex. Let's say, for example, we want all of the counties in the US to the West of `-121` longitude. We need a way to express that question. Ideally, we want something like:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "        *\n",
    "FROM\n",
    "        data_table\n",
    "WHERE\n",
    "        x_centroid < -121\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's refer to an arbitrary polygon in the the dataframe's geometry column as `poly`. We can acquire the centroid of the polygon as a shapely Point. Then we can acquire the coordinates of the point. The longitude is the first element of the pair of the coordinates. \n",
    "\n",
    "Then, applying this condition to each geometry, we get the same kind of filter we used above to grab only counties in Arizona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data_table.geometry[0].centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_table.geometry[0].centroid.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.geometry.apply(lambda x: x.centroid.coords[0][0] < -121)\\\n",
    "                   .head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use this as a filter on the table, we can get only the rows that match that condition, just like we did for the `STATE_NAME` query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[data_table.geometry.apply(lambda x: x.centroid.coords[0][0] < -119)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_table[data_table.geometry.apply(lambda x: x.centroid.coords[0][0] < -119)]) #how many west of -119?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of spatial queries\n",
    "\n",
    "Everybody knows the following statements are true:\n",
    "\n",
    "1. If you head directly west from Reno, Nevada, you will shortly enter California.\n",
    "2. San Diego is in California.\n",
    "\n",
    "But what does this tell us about the location of San Diego relative to Reno?\n",
    "\n",
    "Or for that matter, how many counties in California are to the east of Reno?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = data_table.query('(NAME == \"Washoe\") & (STATE_NAME == \"Nevada\")').geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom.values[0].centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon,lat = geom.values[0].centroid.coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_counties = data_table.query('(STATE_NAME==\"California\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cal_counties[cal_counties.geometry.apply(lambda x: x.centroid.coords[0][0] > lon)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cal_counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works on any type of spatial query. \n",
    "\n",
    "For instance, if we wanted to find all of the counties that are within a threshold distance from an observation's centroid, we can do it in the following way. \n",
    "\n",
    "But first, we need to handle distance calculations on the earth's surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, sqrt, asin\n",
    "\n",
    "def gcd(loc1, loc2, R=3961):\n",
    "    \"\"\"Great circle distance via Haversine formula\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    loc1: tuple (long, lat in decimal degrees)\n",
    "    \n",
    "    loc2: tuple (long, lat in decimal degrees)\n",
    "    \n",
    "    R: Radius of the earth (3961 miles, 6367 km)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    great circle distance between loc1 and loc2 in units of R\n",
    "    \n",
    "    \n",
    "    Notes\n",
    "    ------\n",
    "    Does not take into account non-spheroidal shape of the Earth\n",
    "    \n",
    "    \n",
    "    \n",
    "    >>> san_diego = -117.1611, 32.7157\n",
    "    >>> austin = -97.7431, 30.2672\n",
    "    >>> gcd(san_diego, austin)\n",
    "    1155.474644164695\n",
    "  \n",
    "    \n",
    "    \"\"\"\n",
    "    lon1, lat1 = loc1\n",
    "    lon2, lat2 = loc2\n",
    "    dLat = radians(lat2 - lat1)\n",
    "    dLon = radians(lon2 - lon1)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    " \n",
    "    a = sin(dLat/2)**2 + cos(lat1)*cos(lat2)*sin(dLon/2)**2\n",
    "    c = 2*asin(sqrt(a))\n",
    "\n",
    "    return R * c\n",
    " \n",
    "def gcdm(loc1, loc2):\n",
    "    return gcd(loc1, loc2)\n",
    "\n",
    "def gcdk(loc1, loc2):\n",
    "    return gcd(loc1, loc2, 6367 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego = -117.1611, 32.7157\n",
    "austin = -97.7431, 30.2672\n",
    "gcd(san_diego, austin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcdk(san_diego, austin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = (-117.1611, 0.0)\n",
    "loc2 = (-118.1611, 0.0)\n",
    "gcd(loc1, loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = (-117.1611, 45.0)\n",
    "loc2 = (-118.1611, 45.0)\n",
    "gcd(loc1, loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = (-117.1611, 89.0)\n",
    "loc2 = (-118.1611, 89.0)\n",
    "gcd(loc1, loc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = range(0, 91)\n",
    "onedeglon = [ gcd((-117.1611,lat),(-118.1611,lat)) for lat in lats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(lats, onedeglon)\n",
    "plt.ylabel('miles')\n",
    "plt.xlabel('degree of latitude')\n",
    "plt.title('Length of a degree of longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego = -117.1611, 32.7157\n",
    "austin = -97.7431, 30.2672\n",
    "gcd(san_diego, austin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our distance function to pose distance-related queries on our data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the counties with centroids within 50 miles of Austin\n",
    "def near_target_point(polygon, target=austin, threshold=50):\n",
    "    return gcd(polygon.centroid.coords[0], target) < threshold \n",
    "\n",
    "data_table[data_table.geometry.apply(near_target_point)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving in and out of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most things in PySAL will be explicit about what type their input should be. Most of the time, PySAL functions require either lists or arrays. This is why the file-handler methods are the default IO method in PySAL: the rest of the computational tools are built around their datatypes. \n",
    "\n",
    "However, it is very easy to get the correct datatype from Pandas or Geopandas using the `values` and `tolist` commands. \n",
    "\n",
    "`tolist()` will convert its entries to a list. But, it can only be called on individual columns (called `Series` in `pandas` documentation).\n",
    "\n",
    "So, to turn the `NAME` column into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table.NAME.tolist()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract many columns, you must select the columns you want and call their `.values` attribute. \n",
    "\n",
    "If we were interested in grabbing all of the `HR` variables in the dataframe, we could first select those column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HRs = [col for col in data_table.columns if col.startswith('HR')]\n",
    "HRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to focus only on the columns we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_table[HRs].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, calling `.values` gives an array containing all of the entries in this subset of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table[['HR90', 'HR80']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Find the county with the western most centroid that is within 1000 miles of Austin.\n",
    "2. Find the distance between Austin and that centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "austin_lon = austin[0]\n",
    "west = data_table[data_table.geometry.apply(lambda x: x.centroid.coords[0][0] < austin_lon)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_target_point(polygon, target=austin, threshold=1000):\n",
    "    return gcd(polygon.centroid.coords[0], target) <= threshold \n",
    "\n",
    "west_lt_1000 = west[west.geometry.apply(near_target_point)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxd = 0.\n",
    "county = None\n",
    "for i,row in west_lt_1000.iterrows():\n",
    "    d = gcd(row['geometry'].centroid.coords[0], austin)\n",
    "    if d > maxd:\n",
    "        county = row['NAME']\n",
    "        state = row['STATE_NAME']\n",
    "        maxd = d\n",
    "\n",
    "print('Centroid of %s, %s is %f miles west of Austin'%(county, state, maxd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
